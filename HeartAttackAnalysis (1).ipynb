{"cells":[{"cell_type":"code","source":["#Load Dataset\n\nfrom pyspark.context import SparkContext\nsc=SparkContext.getOrCreate()\n\nheartRdd=sc.textFile(\"/FileStore/tables/data.csv\")\nheartRdd.cache()\nheartRdd.count()"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Remove the first line (contains headers)\nheartRdd = heartRdd.filter(lambda x: \"cp\" not in x)\nheartRdd.count()"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["import math\nfrom pyspark.ml.linalg import Vectors, VectorUDT\n#from pyspark.ml.linalg import Vectors\n\navgChol =sc.broadcast(250)\navgFbs = sc.broadcast(0.06)\navgRrestecg =sc.broadcast(0.21)\navgThalach=sc.broadcast(139.1)\navgExang=sc.broadcast(0.3)\navgSlop=sc.broadcast(1.89)\navgCa=sc.broadcast(0)\navgThal=sc.broadcast(5.6)\navgTres=sc.broadcast(132.5)\n\ndef transformToVector( inputStr) :\n\n    attList=inputStr.split(\",\")    \n    \n    cholValue = attList[4]\n    if cholValue == \"?\":\n        cholValue=avgChol.value\n    fbsValue = attList[5]\n    if fbsValue == \"?\":\n        fbsValue=avgFbs.value\n    restecgValue = attList[6]\n    if restecgValue == \"?\":\n        restecgValue=avgRrestecg.value\n    thalachValue = attList[7]\n    if thalachValue == \"?\":\n        thalachValue=avgThalach.value\n    exangValue = attList[8]\n    if exangValue == \"?\":\n        exangValue=avgExang.value\n    slopValue = attList[10]\n    if slopValue == \"?\":\n        slopValue=avgSlop.value\n    caValue = attList[11]\n    if caValue == \"?\":\n        caValue=avgCa.value\n    thalValue = attList[12]\n    if thalValue == \"?\":\n        thalValue=avgThal.value\n    tresetValue= attList[3]\n    if tresetValue ==\"?\":\n       tresetValue=avgTres.value\n        \n    \n    #Filter out columns not wanted at this stage\n    values= Vectors.dense([float(attList[13]), \\\n                     float(attList[2]),\\\n                     tresetValue,\\\n                     cholValue,  \\\n                     fbsValue,  \\\n                     restecgValue,  \\\n                     thalachValue,  \\\n                     exangValue,  \\\n                     float(attList[9]),\\\n                     slopValue,  \\\n                     caValue, \\\n                     thalValue \\\n                    ])\n\n  \n    return values\n\n\n\n"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["heartVectors = heartRdd.map(transformToVector)\nheartVectors.collect()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["def transformToLabeledPoint(inStr) :\n    labelPoint = (float(inStr[0]), Vectors.dense([inStr[1],inStr[2],inStr[3],inStr[4],inStr[5],inStr[6], inStr[7],inStr[8],inStr[9], inStr[10], inStr[11]]))\n    return labelPoint\n  \nheartLp = heartVectors.map(transformToLabeledPoint)\nheartDF = sqlContext.createDataFrame(heartLp,[\"label\", \"features\"])\nheartDF.select(\"label\",\"features\").show(10)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["(trainingData, testData) = heartDF.randomSplit([0.9, 0.1])\ntrainingData.count()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["testData.count()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Setup pipeline\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nnbClassifier=NaiveBayes()\npipeline = Pipeline(stages=[nbClassifier])\nmodel = pipeline.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["predictions=model.transform(testData)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["predictions.filter(predictions['prediction'] == 0) \\\n    .select(\"label\",\"features\",\"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 23, truncate = 30)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions, {evaluator.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["predictions.groupBy(\"label\",\"prediction\").count().show()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["\ndtClassifer = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\ndtModel = dtClassifer.fit(trainingData)\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["predictions1 = dtModel.transform(testData)\n  \npredictions1.filter(predictions1['prediction'] == 0) \\\n    .select(\"label\",\"features\",\"prediction\") \\\n    .orderBy(\"probability\", ascending=False) \\\n    .show(n = 23, truncate = 30)\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nprint(\"Test: Area Under ROC: \" + str(evaluator.evaluate(predictions1, {evaluator.metricName: \"areaUnderROC\"})))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["prediction1=dtModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["prediction1.groupBy(\"label\",\"prediction\").count().show()"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["accuracy = evaluator.evaluate(predictions1)\nprint(\"Test Error of DTModel = %g\" % (1.0 - accuracy))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["accuracy = evaluator.evaluate(predictions)\nprint(\"Test Error of BCModel = %g\" % (1.0 - accuracy))"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"HeartAttackAnalysis (1)","notebookId":3944356871860316},"nbformat":4,"nbformat_minor":0}
